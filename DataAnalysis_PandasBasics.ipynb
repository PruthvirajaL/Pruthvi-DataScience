{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Let's add this 1st line as a change to the file from Visual studio code."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Added 1st line from cloned system\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Added a 2nd line from visual studio code to this file."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Let us import pandas and look at its version if you find an error \r\n",
    "# please install the pandas using !pip install pandas in jutpyter note book, if exists, it updates to the latest version\r\n",
    "import pandas\r\n",
    "pandas.__version__"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# let us import the pandas as pd in short to save typing time and memory each time we execute the command\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# complete details on pandas can be found at: http://pandas.pydata.org/.\r\n",
    "# in order to check the available pandas documentaion us the command: pd.<TAB>?"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# let us see what pandas is;\r\n",
    "pandas?"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# let us see what pd.read_csv do\r\n",
    "pd.read_csv?"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load the csv file first by its path, if the file exists in the current folder where you are working no need to specify\r\n",
    "# the path, you can type the file name directly \r\n",
    "# it better to start with r\"file path\"\r\n",
    "# we can use different encoding to parse the data, some use utf-8, but there exist many, try which one suits for the file encoding\r\n",
    "location = r\"C:/Users/user/Desktop/Pandas_Essentials/data/global_superstore_2016.csv\"\r\n",
    "gs = pd.read_csv(location, header = 0, encoding ='latin1')\r\n",
    "#gs = pd.read_csv(\"C:/Users/user/Desktop/Pandas_Essentials/data/global_superstore_2016.csv\", sep = ',', header='infer') "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# head() is used to look at first five rows, but we can specify the n= any number of rows, ex: head(10)\n",
    "gs.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# it describs the values\n",
    "gs.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to check the type of the values of the file we can use\n",
    "gs.values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to get the number of rows and its step we can use\n",
    "gs.index"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to slice the rows we can the method,\n",
    "gs[1:5]\n",
    "#gs[0:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to slice in between the range we can use the below method, \n",
    "gs[2:10]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to check the null values we can use isnull, it results in bolean type data with null values filled with True else false\n",
    "gs.isnull().head(20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# this technique is used to drop the null values which are present both in rows and columns\n",
    "gs.dropna(axis = 'columns', how ='all' )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Let ua remove the postal code column that consist lot of null values\n",
    "gsnull = gs.dropna(axis = 'columns')\n",
    "gsnull"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to get the size of the file we can use shape method with the file\n",
    "gs.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# since we have droped the postal code column in the gs file, the number cloumns are reduced by one\n",
    "gsnull.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to check the type of the file we can use type attribute \n",
    "type(gs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# type will yield different type attributes for different types of file, if only one row or column is considered or selected\n",
    "# it reults series\n",
    "type(gs['Row ID'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "type(gs['Order ID'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#gs.Row ID\n",
    "gs['Row ID'].head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# we can select the particular columns as per our data requirement from the original file\n",
    "gs[['Row ID', 'Order ID', 'State', 'Country', 'Market', 'Category', 'Sales', 'Profit']].head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gs[['State', 'Country', 'Market', 'Category', 'Sales', 'Profit']].head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gs[['State', 'Country', 'Region', 'Market', 'Category', 'Sales', 'Profit']].head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gs[['Region', 'Market', 'Category', 'Sub-Category', 'Sales', 'Profit']].head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "type(gs[['State', 'Country', 'Region', 'Market', 'Category', 'Sales', 'Profit']].head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "type(gs.State)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to check  or view data file from the last row we can use tail() \n",
    "gs.tail(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gs.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to get information about the different columns with the null value and type of the data object present we can use info()\n",
    "gs.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to slect only the column with a specific type object we can use equality method\n",
    "gs_CC = gs[gs.Segment == 'Corporate']\n",
    "gs_CC.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(gs_CC.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to count the number of values in the file series we can use value_counts(s)\n",
    "gs_CC.Category.value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gs_CC.City.value_counts().head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gs_CC.Sub-Category.value_counts()\n",
    "# Python allows underscore as the attribute to access the index of the data frame"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gs_CC['Sub-Category'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gs_CCon = gs[gs['Segment'] =='Consumer']\n",
    "gs_CCon.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gs_CCon.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to get the different columns at the same time we use indexing method\n",
    "gs[['Segment', 'Category']].head(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to sort the file with any of the object value or column name we can use sort_values(by='file object name')\n",
    "gs_CCon.sort_values(by ='City')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gs_CCon.sort_values(by ='Sub-Category')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Let us extract the data using conditional statement we can use\n",
    "q_g5 = gs_CCon[gs_CCon['Quantity'] >= 5 ]\n",
    "q_g5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Let us extract the data where the quantity is >= 10\n",
    "q_g10 = gs_CCon[gs_CCon['Quantity'] >= 10 ]\n",
    "q_g10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to get the max value of the column consisting of intger or floating values we can use max() and similarly for minimum, min()\n",
    "q_max = max(gs_CCon['Quantity'])\n",
    "q_max"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q_min = min(gs_CCon['Quantity'])\n",
    "q_min"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}